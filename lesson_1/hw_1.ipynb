{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим предобработку данных с Твиттера, чтобы очищенные данные в дальнейшем\n",
    "использовать для задачи классификации. Данный датасет содержит негативные (label = 1) и нейтральные (label = 0) высказывания. Для работы объединим train_df и test_df.\n",
    "Задания:\n",
    "1. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим\n",
    "функцию:\n",
    "- для того, чтобы найти все вхождения паттерна в тексте, необходимо\n",
    "использовать re.findall(pattern, input_txt)\n",
    "- для замены @user на пробел, необходимо использовать re.sub()\n",
    "2. Изменим регистр твитов на нижний с помощью .lower().\n",
    "3. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя\n",
    "apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в\n",
    "тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в\n",
    "качестве ключа (сокращенного слова), то заменить ключ на значение (полную\n",
    "версию слова).\n",
    "4. Заменим сокращения на их полные формы, используя short_word_dict. Для этого\n",
    "воспользуемся функцией, используемой в предыдущем пункте.\n",
    "5. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict.\n",
    "Для этого воспользуемся функцией, используемой в предыдущем пункте.\n",
    "6. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'.\n",
    "7. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'.\n",
    "8. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'.\n",
    "9. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if\n",
    "len(w)>1]).\n",
    "10. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый\n",
    "столбец 'tweet_token'.\n",
    "11. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец\n",
    "'tweet_token_filtered' без стоп-слов.\n",
    "12. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим\n",
    "столбец 'tweet_stemmed' после применения стемминга.\n",
    "13. Применим лемматизацию к токенам с помощью\n",
    "nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после\n",
    "применения лемматизации.\n",
    "14. Сохраним результат предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dmitriy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dmitriy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dmitriy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import tokenize as tknz\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import pickle\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'/media/dmitriy/Disk/Downloads/ai_nlp_hw_data/hw_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_path, r'train_tweets.csv'))\n",
    "df_test = pd.read_csv(os.path.join(data_path, r'test_tweets.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 3) (17197, 2)\n",
      "(49159, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)\n",
    "df = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pattern(text, pattern):\n",
    "    return re.sub(pattern, ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Удаление @user из всех твитов с помощью паттерна \"@[\\w]*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_for_username = \"@[\\w]*\"\n",
    "df['tweet'] = df['tweet'].apply(lambda x: delete_pattern(x, pattern_for_username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Изменение регистра твитов на нижний с помощью .lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'apostrophe.json', 'r', encoding='utf-8') as f:\n",
    "    apostrophe_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(text, correct_dict):\n",
    "    new_text = ''\n",
    "    for word in text.split():\n",
    "        if word in correct_dict.keys():\n",
    "            new_word = correct_dict[word]\n",
    "        else:\n",
    "            new_word = word\n",
    "        new_text = new_text + ' ' + new_word\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Замена сокращений с апострофами (пример: ain't, can't) на пробел с использованием apostrophe_dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: replace_words(x, apostrophe_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'short_word_dict.json', 'r', encoding='utf-8') as f:\n",
    "    short_word_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Замена сокращений на их полные формы с использованием short_word_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: replace_words(x, short_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'emoticon_dict.json', 'r', encoding='utf-8') as f:\n",
    "    emoticon_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Замена эмотиконов (пример: \":)\" = \"happy\") на пробелы с использованием emoticon_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: replace_words(x, emoticon_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_punctuation(text, pattern_for_punctuation):\n",
    "    return re.sub(pattern_for_punctuation, ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Замена пунктуации на пробелы с использованием re.sub() и паттерна r'[^\\w\\s]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_for_punctuation = r'[^\\w\\s]'\n",
    "df['tweet'] = df['tweet'].apply(lambda x: delete_pattern(x, pattern_for_punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_special_symb(text, pattern_for_special_symb):\n",
    "    return re.sub(pattern_for_special_symb, ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Замена спец. символов на пробелы с использованием re.sub() и паттерна r'[^a-zA-Z0-9]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_for_special_symb = r'[^a-zA-Z0-9]'\n",
    "df['tweet'] = df['tweet'].apply(lambda x: delete_pattern(x, pattern_for_special_symb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_short_words(text, min_len):\n",
    "    return ' '.join([word for word in text.split() if len(word) > min_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Замена чисел на пробелы с использованием re.sub() и паттерна r'[^a-zA-Z]'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_for_numbers = r'[^a-zA-Z]'\n",
    "df['tweet'] = df['tweet'].apply(lambda x: delete_pattern(x, pattern_for_special_symb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Удаление из текста слова длиной в 1 символ с использованием конструкции ' '.join([w for w in x.split() if len(w)>1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = 1\n",
    "df['tweet'] = df['tweet'].apply(lambda x: delete_short_words(x, min_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...\n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...\n",
       "2   3    0.0                                bihday your majesty\n",
       "3   4    0.0    model love you take with you all the time in ur\n",
       "4   5    0.0                  factsguide society now motivation"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Деление твитов на токены с помощью nltk.tokenize.word_tokenize с созданием нового столбца 'tweet_token'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_token'] = df['tweet'].apply(lambda x: tknz.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \n",
       "0  [when, father, is, dysfunctional, and, is, so,...  \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...  \n",
       "2                            [bihday, your, majesty]  \n",
       "3  [model, love, you, take, with, you, all, the, ...  \n",
       "4             [factsguide, society, now, motivation]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stop_words(text, stop_words):\n",
    "    return ' '.join([word for word in text if word not in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Удаление стоп-слов из токенов с использованием nltk.corpus.stopwords. Создание столбца 'tweet_token_filtered' без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"russian\"))\n",
    "df['tweet_token_filtered'] = df['tweet_token'].apply(lambda x: delete_stop_words(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_stemmer(text, stemmer):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Применение стемминга к токенам с помощью nltk.stem.PorterStemmer. Создание столбца 'tweet_stemmed' после применения стемминга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "df['tweet_stemmed'] = df['tweet_token_filtered'].apply(lambda x: compare_stemmer(x, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lemmatizer(text, lemmatizer):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Применение лемматизации к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создание столбца 'tweet_lemmatized' после применения лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['tweet_lemmatized'] = df['tweet_token_filtered'].apply(lambda x: compare_lemmatizer(x, lemmatizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>when father is dysfunct and is so selfish he d...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>thanks for lyft credit can not use cause they ...</td>\n",
       "      <td>thank for lyft credit can not use caus they do...</td>\n",
       "      <td>thanks for lyft credit can not use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesti</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>factsguid societi now motiv</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>huge fan fare and big talking before they leav...</td>\n",
       "      <td>[huge, fan, fare, and, big, talking, before, t...</td>\n",
       "      <td>huge fan fare and big talking before they leav...</td>\n",
       "      <td>huge fan fare and big talk befor they leav cha...</td>\n",
       "      <td>huge fan fare and big talking before they leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>camping tomorrow danny</td>\n",
       "      <td>[camping, tomorrow, danny]</td>\n",
       "      <td>camping tomorrow danny</td>\n",
       "      <td>camp tomorrow danni</td>\n",
       "      <td>camping tomorrow danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the next school year is the year for exams can...</td>\n",
       "      <td>[the, next, school, year, is, the, year, for, ...</td>\n",
       "      <td>the next school year is the year for exams can...</td>\n",
       "      <td>the next school year is the year for exam can ...</td>\n",
       "      <td>the next school year is the year for exam can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we won love the land allin cavs champions clev...</td>\n",
       "      <td>[we, won, love, the, land, allin, cavs, champi...</td>\n",
       "      <td>we won love the land allin cavs champions clev...</td>\n",
       "      <td>we won love the land allin cav champion clevel...</td>\n",
       "      <td>we won love the land allin cavs champion cleve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>welcome here am it has it is so gr8</td>\n",
       "      <td>[welcome, here, am, it, has, it, is, so, gr8]</td>\n",
       "      <td>welcome here am it has it is so gr8</td>\n",
       "      <td>welcom here am it ha it is so gr8</td>\n",
       "      <td>welcome here am it ha it is so gr8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "5   6    0.0  huge fan fare and big talking before they leav...   \n",
       "6   7    0.0                             camping tomorrow danny   \n",
       "7   8    0.0  the next school year is the year for exams can...   \n",
       "8   9    0.0  we won love the land allin cavs champions clev...   \n",
       "9  10    0.0                welcome here am it has it is so gr8   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "5  [huge, fan, fare, and, big, talking, before, t...   \n",
       "6                         [camping, tomorrow, danny]   \n",
       "7  [the, next, school, year, is, the, year, for, ...   \n",
       "8  [we, won, love, the, land, allin, cavs, champi...   \n",
       "9      [welcome, here, am, it, has, it, is, so, gr8]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit can not use cause they ...   \n",
       "2                                bihday your majesty   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "5  huge fan fare and big talking before they leav...   \n",
       "6                             camping tomorrow danny   \n",
       "7  the next school year is the year for exams can...   \n",
       "8  we won love the land allin cavs champions clev...   \n",
       "9                welcome here am it has it is so gr8   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  when father is dysfunct and is so selfish he d...   \n",
       "1  thank for lyft credit can not use caus they do...   \n",
       "2                                bihday your majesti   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                        factsguid societi now motiv   \n",
       "5  huge fan fare and big talk befor they leav cha...   \n",
       "6                                camp tomorrow danni   \n",
       "7  the next school year is the year for exam can ...   \n",
       "8  we won love the land allin cav champion clevel...   \n",
       "9                  welcom here am it ha it is so gr8   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  when father is dysfunctional and is so selfish...  \n",
       "1  thanks for lyft credit can not use cause they ...  \n",
       "2                                bihday your majesty  \n",
       "3    model love you take with you all the time in ur  \n",
       "4                  factsguide society now motivation  \n",
       "5  huge fan fare and big talking before they leav...  \n",
       "6                             camping tomorrow danny  \n",
       "7  the next school year is the year for exam can ...  \n",
       "8  we won love the land allin cavs champion cleve...  \n",
       "9                 welcome here am it ha it is so gr8  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Сохранение результата предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'nlp_hw_1_results.pickle', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'nlp_hw_1_results.pickle', 'rb') as f:\n",
    "    df_check = pickle.load(f, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>when father is dysfunct and is so selfish he d...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>thanks for lyft credit can not use cause they ...</td>\n",
       "      <td>thank for lyft credit can not use caus they do...</td>\n",
       "      <td>thanks for lyft credit can not use cause they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesti</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>[model, love, you, take, with, you, all, the, ...</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>factsguid societi now motiv</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0    model love you take with you all the time in ur   \n",
       "4   5    0.0                  factsguide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, love, you, take, with, you, all, the, ...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit can not use cause they ...   \n",
       "2                                bihday your majesty   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  when father is dysfunct and is so selfish he d...   \n",
       "1  thank for lyft credit can not use caus they do...   \n",
       "2                                bihday your majesti   \n",
       "3    model love you take with you all the time in ur   \n",
       "4                        factsguid societi now motiv   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  when father is dysfunctional and is so selfish...  \n",
       "1  thanks for lyft credit can not use cause they ...  \n",
       "2                                bihday your majesty  \n",
       "3    model love you take with you all the time in ur  \n",
       "4                  factsguide society now motivation  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
